{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PIAIC-Q2-DL - Assignment - Flowers Recognition (Completed).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXgJ6uT1NydQ"
      },
      "source": [
        "Assignment: Flowers Recognition <br>\n",
        "Dataset Description:<br>\n",
        "\n",
        "This dataset contains 4242 images of flowers.<br>\n",
        "The data collection is based on the data flicr, google images, yandex images.<br>\n",
        "You can use this datastet to recognize plants from the photo.<br>\n",
        "\n",
        "Attribute Information:<br>\n",
        "The pictures are divided into five classes: chamomile, tulip, rose, sunflower, dandelion.<br>\n",
        "For each class there are about 800 photos. Photos are not high resolution, about 320x240 pixels. <br>\n",
        "<b>Also explore how to resize images in tensorflow and then resize all the images to a same size. </b> <br>\n",
        "This is a Multiclass Classification Problem.<br>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7vy-ktuOKJH"
      },
      "source": [
        "WORKFLOW : <br>\n",
        "Load Data <br>\n",
        "Split into 60 and 40 ratio.<br>\n",
        "Encode labels.<br>\n",
        "Create Model<br>\n",
        "Compilation Step (Note : Its a Multiclass Classification problem , select loss , metrics according to it)<br>\n",
        "Train the Model.<br>\n",
        "If the model gets overfit tune your model by changing the units , No. of layers , epochs , add dropout layer or add Regularizer according to the need .<br>\n",
        "Prediction should be > 85%<br>\n",
        "Evaluation Step<br>\n",
        "Prediction<br>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ri3Bg5qfPRic"
      },
      "source": [
        "Data : <br>\n",
        "https://drive.google.com/file/d/1-OX6wn5gA-bJpjPNfSyaYQLz-A-AB_uj/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTtg3WuGTA1o"
      },
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "import tensorflow_datasets as tfds\n",
        "from google.colab import drive\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow import nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJ6foO6S0Frs",
        "outputId": "679c67f1-5ace-4eb7-82ee-9156f895b54a"
      },
      "source": [
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWKAQ55G7d0q"
      },
      "source": [
        "MAIN_DIR = \"/content/drive/MyDrive/PIAIC/assignment_resources/flowers/\"\n",
        "classes = [\"tulip\", \"sunflower\", \"rose\", \"dandelion\", \"daisy\"]\n",
        "x_list=[]\n",
        "y_list=[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Z260l9uWUTOC",
        "outputId": "9123e10e-e1a1-4566-884b-3b36629cf02e"
      },
      "source": [
        "count = 0\n",
        "perc = 0\n",
        "for i, c in enumerate(classes):\n",
        "  path = join(MAIN_DIR, c)\n",
        "  files = [f for f in listdir(path) if isfile(join(path, f))]\n",
        "\n",
        "  for i2, file in enumerate(files):\n",
        "    img_path = join(path, file)\n",
        "    try:\n",
        "      arr = np.asarray(Image.open(img_path).resize((35,35)))\n",
        "      x_list.append(arr)\n",
        "      y_list.append(i)\n",
        "    except Exception as e:\n",
        "      print(\"An error occured\")\n",
        "      print(e)\n",
        "      pass\n",
        "    count += 1\n",
        "    perc_new = round(count / 4325 * 100) \n",
        "    if(perc_new == perc):\n",
        "      pass\n",
        "    else:\n",
        "      perc = perc_new\n",
        "      print(f\"{perc}% done\")\n",
        "\n",
        "\n",
        "x = np.array(x_list)\n",
        "y = np.array(y_list)\n",
        "\n",
        "np.savez(\"pil-flowers-arrays.npz\", x=x, y=y)\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1% done\n",
            "2% done\n",
            "3% done\n",
            "4% done\n",
            "5% done\n",
            "6% done\n",
            "7% done\n",
            "8% done\n",
            "9% done\n",
            "10% done\n",
            "11% done\n",
            "12% done\n",
            "13% done\n",
            "14% done\n",
            "15% done\n",
            "16% done\n",
            "17% done\n",
            "18% done\n",
            "19% done\n",
            "20% done\n",
            "21% done\n",
            "22% done\n",
            "23% done\n",
            "24% done\n",
            "25% done\n",
            "26% done\n",
            "27% done\n",
            "28% done\n",
            "29% done\n",
            "30% done\n",
            "31% done\n",
            "32% done\n",
            "33% done\n",
            "34% done\n",
            "35% done\n",
            "36% done\n",
            "37% done\n",
            "38% done\n",
            "39% done\n",
            "40% done\n",
            "41% done\n",
            "42% done\n",
            "43% done\n",
            "44% done\n",
            "45% done\n",
            "46% done\n",
            "47% done\n",
            "48% done\n",
            "49% done\n",
            "50% done\n",
            "51% done\n",
            "52% done\n",
            "53% done\n",
            "54% done\n",
            "55% done\n",
            "56% done\n",
            "57% done\n",
            "58% done\n",
            "59% done\n",
            "60% done\n",
            "61% done\n",
            "62% done\n",
            "63% done\n",
            "64% done\n",
            "65% done\n",
            "66% done\n",
            "67% done\n",
            "68% done\n",
            "69% done\n",
            "70% done\n",
            "71% done\n",
            "72% done\n",
            "73% done\n",
            "74% done\n",
            "75% done\n",
            "76% done\n",
            "77% done\n",
            "An error occured\n",
            "cannot identify image file '/content/drive/MyDrive/PIAIC/assignment_resources/flowers/dandelion/flickr.py'\n",
            "An error occured\n",
            "cannot identify image file '/content/drive/MyDrive/PIAIC/assignment_resources/flowers/dandelion/run_me.py'\n",
            "78% done\n",
            "79% done\n",
            "80% done\n",
            "An error occured\n",
            "cannot identify image file '/content/drive/MyDrive/PIAIC/assignment_resources/flowers/dandelion/flickr.pyc'\n",
            "81% done\n",
            "82% done\n",
            "83% done\n",
            "84% done\n",
            "85% done\n",
            "86% done\n",
            "87% done\n",
            "88% done\n",
            "89% done\n",
            "90% done\n",
            "91% done\n",
            "92% done\n",
            "93% done\n",
            "94% done\n",
            "95% done\n",
            "96% done\n",
            "97% done\n",
            "98% done\n",
            "99% done\n",
            "100% done\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-8ee4defde5f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (35,35,3) into shape (35,35)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQZ6J7RXxRzw"
      },
      "source": [
        "saved_arrays = np.load(\"pil-flowers-arrays.npz\")\n",
        "\n",
        "x = saved_arrays[\"x\"]\n",
        "y = saved_arrays[\"y\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeVw-AqiPiU2"
      },
      "source": [
        "print(x.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfj1AdXzPklm"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrEdoi12Q4-Q"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print()\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yBTPUPNdDeH"
      },
      "source": [
        "x_train_partial = x_train[0:2076]\n",
        "y_train_partial = y_train[0:2076]\n",
        "\n",
        "x_val = x_train[2076:]\n",
        "y_val = y_train[2076:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bza56vugtp50"
      },
      "source": [
        "print(x_train_partial.shape)\n",
        "print(y_train_partial.shape)\n",
        "\n",
        "print(x_val.shape)\n",
        "print(y_val.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pgte5mrJRZK8"
      },
      "source": [
        "idx = 7\n",
        "img = Image.fromarray(x_train_partial[idx])\n",
        "img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwhNhy6MR6zE"
      },
      "source": [
        "classes[y_train_partial[idx]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dih2yyzdft0c"
      },
      "source": [
        "img = Image.fromarray(x_val[idx])\n",
        "img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPbRZ6x_fsnE"
      },
      "source": [
        "|classes[y_val[idx]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5yR2QraWSHy"
      },
      "source": [
        "x_train_partial = x_train_partial.reshape((x_train_partial.shape[0], x_train_partial.shape[1] * x_train_partial.shape[2] * x_train_partial.shape[3]))\n",
        "# x_train_partial = x_train_partial.reshape((x_train_partial.shape[0], x_train_partial.shape[1] * x_train_partial.shape[2]))\n",
        "x_train_partial = x_train_partial / 255\n",
        "# x_train_partial = (x_train_partial - x_train_partial.mean(axis=0)) / x_train_partial.std(axis=0)\n",
        "\n",
        "x_val = x_val.reshape((x_val.shape[0], x_val.shape[1] * x_val.shape[2] * x_val.shape[3]))\n",
        "# x_val = x_val.reshape((x_val.shape[0], x_val.shape[1] * x_val.shape[2]))\n",
        "x_val = x_val / 255\n",
        "# x_val = (x_val - x_val.mean(axis=0)) / x_val.std(axis=0)\n",
        "\n",
        "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1] * x_test.shape[2] * x_test.shape[3]))\n",
        "# x_test = x_test.reshape((x_test.shape[0], x_test.shape[1] * x_test.shape[2]))\n",
        "x_test = x_test / 255\n",
        "# x_val = (x_val - x_val.mean(axis=0)) / x_val.std(axis=0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ieeos2IaTrn"
      },
      "source": [
        "y_train_partial = to_categorical(y_train_partial)\n",
        "y_val = to_categorical(y_val)\n",
        "y_test = to_categorical(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSWNSXiWSaW8"
      },
      "source": [
        "network = Sequential()\n",
        "network.add(layers.Dense(512, activation=\"relu\", input_shape=(x_train_partial.shape[1], )))\n",
        "network.add(layers.Dense(512, activation=\"relu\"))\n",
        "network.add(layers.Dense(512, activation=\"relu\"))\n",
        "network.add(layers.Dense(512, activation=\"relu\"))\n",
        "network.add(layers.Dense(512, activation=\"relu\"))\n",
        "network.add(layers.Dense(512, activation=\"relu\"))\n",
        "network.add(layers.Dense(5, activation=\"softmax\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Wgr9xpglRYA"
      },
      "source": [
        "network.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ak6d6fqfajOF"
      },
      "source": [
        "history = network.fit(x_train_partial, y_train_partial, epochs=20, validation_data=(x_val, y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eS4wbrIQzqfj"
      },
      "source": [
        "plt.clf()\n",
        "loss = history.history[\"loss\"]\n",
        "val_loss = history.history[\"val_loss\"]\n",
        "\n",
        "epochs = range(1, len(loss) + 1)\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGRonwhEA65X"
      },
      "source": [
        "plt.clf()\n",
        "accuracy = history.history[\"accuracy\"]\n",
        "val_accuracy = history.history[\"val_accuracy\"]\n",
        "\n",
        "epochs = range(1, len(accuracy) + 1)\n",
        "\n",
        "plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnxTEgpYbNoD",
        "outputId": "5822d6b6-625c-497c-96e7-f99a59a7f368"
      },
      "source": [
        "network.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "55/55 [==============================] - 0s 8ms/step - loss: 2.1058 - accuracy: 0.4052\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.1057791709899902, 0.40520229935646057]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdqznEb81ABT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}